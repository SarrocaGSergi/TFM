# Synthesising Images from text Descriptions

#### ABSTRACT
Synthesising images from text descriptions has become one of the most important research fields of computer vision in the last few years. In this field the aim is to understand spatial relations between the objects described and their position in the image, composing realistic images from these relationships. In this project, state-of-the-art text-to-image synthesis methods are studied and evaluated using the FashionGen dataset in order to study their behaviour, creating a fashion generator application as a result. We propose a text-to-image synthesis method to automatically generate clothing fashion images from natural language descriptions. The image generation is based on a Generative Adversarial Network trained using the FashionGen dataset, while the input is based on natural language descriptions processed by a text encoder with an attention mechanism.


> Google Slides: https://docs.google.com/presentation/d/1nCwbefOx-rrPQlFhCvmk8oVeEe0K-IX3fToiJn9An2c/edit?usp=sharing
